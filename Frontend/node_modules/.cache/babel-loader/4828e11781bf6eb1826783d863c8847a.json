{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport { ok as assert } from 'uvu/assert';\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\nimport { codes } from 'micromark-util-symbol/codes.js';\nimport { constants } from 'micromark-util-symbol/constants.js';\nimport { types } from 'micromark-util-symbol/types.js';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\n\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n/** @type {Construct} */\n\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\n\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous;\n  return start;\n  /** @type {State} */\n\n  function start(code) {\n    assert(code !== codes.eof && !markdownLineEnding(code), 'expected no eof or eol');\n    effects.enter(types.content);\n    previous = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent\n    });\n    return data(code);\n  }\n  /** @type {State} */\n\n\n  function data(code) {\n    if (code === codes.eof) {\n      return contentEnd(code);\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    } // Data.\n\n\n    effects.consume(code);\n    return data;\n  }\n  /** @type {State} */\n\n\n  function contentEnd(code) {\n    effects.exit(types.chunkContent);\n    effects.exit(types.content);\n    return ok(code);\n  }\n  /** @type {State} */\n\n\n  function contentContinue(code) {\n    assert(markdownLineEnding(code), 'expected eol');\n    effects.consume(code);\n    effects.exit(types.chunkContent);\n    previous.next = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent,\n      previous\n    });\n    previous = previous.next;\n    return data;\n  }\n}\n/** @type {Tokenizer} */\n\n\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n  /** @type {State} */\n\n  function startLookahead(code) {\n    assert(markdownLineEnding(code), 'expected a line ending');\n    effects.exit(types.chunkContent);\n    effects.enter(types.lineEnding);\n    effects.consume(code);\n    effects.exit(types.lineEnding);\n    return factorySpace(effects, prefixed, types.linePrefix);\n  }\n  /** @type {State} */\n\n\n  function prefixed(code) {\n    if (code === codes.eof || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    const tail = self.events[self.events.length - 1];\n\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === types.linePrefix && tail[2].sliceSerialize(tail[1], true).length >= constants.tabSize) {\n      return ok(code);\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}","map":{"version":3,"names":["ok","assert","factorySpace","markdownLineEnding","subtokenize","codes","constants","types","content","tokenize","tokenizeContent","resolve","resolveContent","continuationConstruct","tokenizeContinuation","partial","events","effects","previous","start","code","eof","enter","chunkContent","contentType","contentTypeContent","data","contentEnd","check","contentContinue","consume","exit","next","nok","self","startLookahead","lineEnding","prefixed","linePrefix","tail","length","parser","constructs","disable","null","includes","type","sliceSerialize","tabSize","interrupt","flow"],"sources":["C:/Users/hecto/source/repos/React-Projects/covered/Covered/node_modules/micromark-core-commonmark/dev/lib/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\n\nimport {ok as assert} from 'uvu/assert'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {subtokenize} from 'micromark-util-subtokenize'\nimport {codes} from 'micromark-util-symbol/codes.js'\nimport {constants} from 'micromark-util-symbol/constants.js'\nimport {types} from 'micromark-util-symbol/types.js'\n\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {tokenize: tokenizeContent, resolve: resolveContent}\n\n/** @type {Construct} */\nconst continuationConstruct = {tokenize: tokenizeContinuation, partial: true}\n\n/**\n * Content is transparent: it’s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events)\n  return events\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token} */\n  let previous\n\n  return start\n\n  /** @type {State} */\n  function start(code) {\n    assert(\n      code !== codes.eof && !markdownLineEnding(code),\n      'expected no eof or eol'\n    )\n\n    effects.enter(types.content)\n    previous = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent\n    })\n    return data(code)\n  }\n\n  /** @type {State} */\n  function data(code) {\n    if (code === codes.eof) {\n      return contentEnd(code)\n    }\n\n    if (markdownLineEnding(code)) {\n      return effects.check(\n        continuationConstruct,\n        contentContinue,\n        contentEnd\n      )(code)\n    }\n\n    // Data.\n    effects.consume(code)\n    return data\n  }\n\n  /** @type {State} */\n  function contentEnd(code) {\n    effects.exit(types.chunkContent)\n    effects.exit(types.content)\n    return ok(code)\n  }\n\n  /** @type {State} */\n  function contentContinue(code) {\n    assert(markdownLineEnding(code), 'expected eol')\n    effects.consume(code)\n    effects.exit(types.chunkContent)\n    previous.next = effects.enter(types.chunkContent, {\n      contentType: constants.contentTypeContent,\n      previous\n    })\n    previous = previous.next\n    return data\n  }\n}\n\n/** @type {Tokenizer} */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this\n\n  return startLookahead\n\n  /** @type {State} */\n  function startLookahead(code) {\n    assert(markdownLineEnding(code), 'expected a line ending')\n    effects.exit(types.chunkContent)\n    effects.enter(types.lineEnding)\n    effects.consume(code)\n    effects.exit(types.lineEnding)\n    return factorySpace(effects, prefixed, types.linePrefix)\n  }\n\n  /** @type {State} */\n  function prefixed(code) {\n    if (code === codes.eof || markdownLineEnding(code)) {\n      return nok(code)\n    }\n\n    const tail = self.events[self.events.length - 1]\n\n    if (\n      !self.parser.constructs.disable.null.includes('codeIndented') &&\n      tail &&\n      tail[1].type === types.linePrefix &&\n      tail[2].sliceSerialize(tail[1], true).length >= constants.tabSize\n    ) {\n      return ok(code)\n    }\n\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code)\n  }\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAAQA,EAAE,IAAIC,MAAd,QAA2B,YAA3B;AACA,SAAQC,YAAR,QAA2B,yBAA3B;AACA,SAAQC,kBAAR,QAAiC,0BAAjC;AACA,SAAQC,WAAR,QAA0B,4BAA1B;AACA,SAAQC,KAAR,QAAoB,gCAApB;AACA,SAAQC,SAAR,QAAwB,oCAAxB;AACA,SAAQC,KAAR,QAAoB,gCAApB;AAEA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,OAAO,GAAG;EAACC,QAAQ,EAAEC,eAAX;EAA4BC,OAAO,EAAEC;AAArC,CAAhB;AAEP;;AACA,MAAMC,qBAAqB,GAAG;EAACJ,QAAQ,EAAEK,oBAAX;EAAiCC,OAAO,EAAE;AAA1C,CAA9B;AAEA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASH,cAAT,CAAwBI,MAAxB,EAAgC;EAC9BZ,WAAW,CAACY,MAAD,CAAX;EACA,OAAOA,MAAP;AACD;AAED;;;AACA,SAASN,eAAT,CAAyBO,OAAzB,EAAkCjB,EAAlC,EAAsC;EACpC;EACA,IAAIkB,QAAJ;EAEA,OAAOC,KAAP;EAEA;;EACA,SAASA,KAAT,CAAeC,IAAf,EAAqB;IACnBnB,MAAM,CACJmB,IAAI,KAAKf,KAAK,CAACgB,GAAf,IAAsB,CAAClB,kBAAkB,CAACiB,IAAD,CADrC,EAEJ,wBAFI,CAAN;IAKAH,OAAO,CAACK,KAAR,CAAcf,KAAK,CAACC,OAApB;IACAU,QAAQ,GAAGD,OAAO,CAACK,KAAR,CAAcf,KAAK,CAACgB,YAApB,EAAkC;MAC3CC,WAAW,EAAElB,SAAS,CAACmB;IADoB,CAAlC,CAAX;IAGA,OAAOC,IAAI,CAACN,IAAD,CAAX;EACD;EAED;;;EACA,SAASM,IAAT,CAAcN,IAAd,EAAoB;IAClB,IAAIA,IAAI,KAAKf,KAAK,CAACgB,GAAnB,EAAwB;MACtB,OAAOM,UAAU,CAACP,IAAD,CAAjB;IACD;;IAED,IAAIjB,kBAAkB,CAACiB,IAAD,CAAtB,EAA8B;MAC5B,OAAOH,OAAO,CAACW,KAAR,CACLf,qBADK,EAELgB,eAFK,EAGLF,UAHK,EAILP,IAJK,CAAP;IAKD,CAXiB,CAalB;;;IACAH,OAAO,CAACa,OAAR,CAAgBV,IAAhB;IACA,OAAOM,IAAP;EACD;EAED;;;EACA,SAASC,UAAT,CAAoBP,IAApB,EAA0B;IACxBH,OAAO,CAACc,IAAR,CAAaxB,KAAK,CAACgB,YAAnB;IACAN,OAAO,CAACc,IAAR,CAAaxB,KAAK,CAACC,OAAnB;IACA,OAAOR,EAAE,CAACoB,IAAD,CAAT;EACD;EAED;;;EACA,SAASS,eAAT,CAAyBT,IAAzB,EAA+B;IAC7BnB,MAAM,CAACE,kBAAkB,CAACiB,IAAD,CAAnB,EAA2B,cAA3B,CAAN;IACAH,OAAO,CAACa,OAAR,CAAgBV,IAAhB;IACAH,OAAO,CAACc,IAAR,CAAaxB,KAAK,CAACgB,YAAnB;IACAL,QAAQ,CAACc,IAAT,GAAgBf,OAAO,CAACK,KAAR,CAAcf,KAAK,CAACgB,YAApB,EAAkC;MAChDC,WAAW,EAAElB,SAAS,CAACmB,kBADyB;MAEhDP;IAFgD,CAAlC,CAAhB;IAIAA,QAAQ,GAAGA,QAAQ,CAACc,IAApB;IACA,OAAON,IAAP;EACD;AACF;AAED;;;AACA,SAASZ,oBAAT,CAA8BG,OAA9B,EAAuCjB,EAAvC,EAA2CiC,GAA3C,EAAgD;EAC9C,MAAMC,IAAI,GAAG,IAAb;EAEA,OAAOC,cAAP;EAEA;;EACA,SAASA,cAAT,CAAwBf,IAAxB,EAA8B;IAC5BnB,MAAM,CAACE,kBAAkB,CAACiB,IAAD,CAAnB,EAA2B,wBAA3B,CAAN;IACAH,OAAO,CAACc,IAAR,CAAaxB,KAAK,CAACgB,YAAnB;IACAN,OAAO,CAACK,KAAR,CAAcf,KAAK,CAAC6B,UAApB;IACAnB,OAAO,CAACa,OAAR,CAAgBV,IAAhB;IACAH,OAAO,CAACc,IAAR,CAAaxB,KAAK,CAAC6B,UAAnB;IACA,OAAOlC,YAAY,CAACe,OAAD,EAAUoB,QAAV,EAAoB9B,KAAK,CAAC+B,UAA1B,CAAnB;EACD;EAED;;;EACA,SAASD,QAAT,CAAkBjB,IAAlB,EAAwB;IACtB,IAAIA,IAAI,KAAKf,KAAK,CAACgB,GAAf,IAAsBlB,kBAAkB,CAACiB,IAAD,CAA5C,EAAoD;MAClD,OAAOa,GAAG,CAACb,IAAD,CAAV;IACD;;IAED,MAAMmB,IAAI,GAAGL,IAAI,CAAClB,MAAL,CAAYkB,IAAI,CAAClB,MAAL,CAAYwB,MAAZ,GAAqB,CAAjC,CAAb;;IAEA,IACE,CAACN,IAAI,CAACO,MAAL,CAAYC,UAAZ,CAAuBC,OAAvB,CAA+BC,IAA/B,CAAoCC,QAApC,CAA6C,cAA7C,CAAD,IACAN,IADA,IAEAA,IAAI,CAAC,CAAD,CAAJ,CAAQO,IAAR,KAAiBvC,KAAK,CAAC+B,UAFvB,IAGAC,IAAI,CAAC,CAAD,CAAJ,CAAQQ,cAAR,CAAuBR,IAAI,CAAC,CAAD,CAA3B,EAAgC,IAAhC,EAAsCC,MAAtC,IAAgDlC,SAAS,CAAC0C,OAJ5D,EAKE;MACA,OAAOhD,EAAE,CAACoB,IAAD,CAAT;IACD;;IAED,OAAOH,OAAO,CAACgC,SAAR,CAAkBf,IAAI,CAACO,MAAL,CAAYC,UAAZ,CAAuBQ,IAAzC,EAA+CjB,GAA/C,EAAoDjC,EAApD,EAAwDoB,IAAxD,CAAP;EACD;AACF"},"metadata":{},"sourceType":"module"}